# ğŸ‘§ğŸ¼ HELLA â€“ Your Personal AI Assistant

HELLA is a **real-time multimodal AI agent** that listens, thinks, looks, and responds like a human.  
It combines **LLMs, speech, and vision** to create a seamless AI assistant experience.

---

## **ğŸš€ Features**

| Function | Tech Used |
|-----------|-----------|
| **Talk to You (Speech-to-Text)** | **Whisper Large V3 (Groq API)** |
| **Talk Back (Text-to-Speech)** | **ElevenLabs API** |
| **Answer Questions & Reasoning** | **Gemini-2.0-Flash (Google Generative AI)** |
| **See Through Camera** | **LLaMA-4 Maverick Vision Model (Groq Vision API)** |
| **Real-Time UI** | **Gradio Interface** |
| **Agentic Decision Making** | **LangGraph ReAct Agent** |

---

## **ğŸ§  How It Works**

1. **Continuous Listening**  
   HELLA listens to your voice input using **Whisper STT**.

2. **Agentic Reasoning**  
   Uses a **ReAct Agent (LangGraph)** with **Gemini-2.0-Flash** to process the query.

3. **Vision Capabilities**  
   If the query needs visual input (like "Do I have my phone in my hand?"), HELLA:
   - Captures an image via webcam  
   - Sends it to **LLaMA-4 Maverick Vision LLM** via Groq

4. **Natural Speech Output**  
   Responds with human-like audio using **ElevenLabs TTS**.

---

## **ğŸ§° Tech Stack**

- **LLMs**: Gemini-2.0-Flash, LLaMA-4 Maverick  
- **Speech-to-Text**: Whisper Large V3 via Groq API  
- **Text-to-Speech**: ElevenLabs  
- **Vision**: Groq Vision API  
- **Framework**: Gradio  
- **Environment & Package Management**: `uv` (Rust-based Python tool)

---

## **ğŸ“¦ Why `uv`?**

Instead of `pip + venv`, this project uses **`uv`** for:

- âš¡ **10x faster package installs**  
- ğŸ”’ **Deterministic builds** with lockfiles  
- ğŸš€ **Modern tooling**, no venv setup hassle  
- ğŸ¦€ **Rust-powered speed**

---

## **ğŸ“‚ Project Structure**
